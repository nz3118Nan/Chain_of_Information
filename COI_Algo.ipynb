{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"utils/\")\n",
    "\n",
    "from Verification_Data_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy_df_generation function\n",
    "def entropy_df_generation(dic_result,n_round = 3):\n",
    "    df = pd.DataFrame(columns=[\"token\", 'logprob'])\n",
    "    for i in range(n_round):\n",
    "        result_i = dic_result[i][\"choices\"]\n",
    "        if '{' in  result_i[0][\"logprobs\"][\"tokens\"]:\n",
    "            index = result_i[0][\"logprobs\"][\"tokens\"].index('{')\n",
    "        else:\n",
    "            index = result_i[0][\"logprobs\"][\"tokens\"].index(' {')\n",
    "        sample_token = result_i[0][\"logprobs\"][\"tokens\"][index+1]\n",
    "        sample_token_logprob = result_i[0][\"logprobs\"][\"token_logprobs\"][index+1]\n",
    "        df.loc[len(df)] = [sample_token, sample_token_logprob]  \n",
    "        log_list = result_i[0][\"logprobs\"][\"top_logprobs\"][index+1]\n",
    "        for key in list(log_list.keys()):\n",
    "            df.loc[len(df)] = [key, log_list[key]]\n",
    "    df_result = pd.DataFrame(columns=[\"token\", 'logprob'])\n",
    "    for token in np.unique(df[\"token\"]):\n",
    "        df_result.loc[len(df_result)] = [token, np.mean(df[df[\"token\"] == token][\"logprob\"])]\n",
    "    df_result[\"prob\"] = np.exp(df_result[\"logprob\"])\n",
    "    df_result[\"prob\"] = df_result[\"prob\"]/np.sum(df_result[\"prob\"])\n",
    "    df_result[\"logprob\"] = np.log(df_result[\"prob\"])\n",
    "    df_result = df_result.sort_values(by = \"prob\", ascending = False).reset_index(drop=True)\n",
    "    df_result[\"cumprob\"] = np.cumsum(df_result[\"prob\"])\n",
    "    df_result_majority = df_result[df_result[\"cumprob\"] < 1] \n",
    "    df_result_majority = df_result_majority[[i.replace(' ','').isnumeric() for i in df_result_majority[\"token\"]]].reset_index(drop=True)\n",
    "    df_result_majority[\"prob\"] = np.exp(df_result_majority[\"logprob\"])\n",
    "    df_result_majority[\"prob\"] = df_result_majority[\"prob\"]/np.sum(df_result_majority[\"prob\"])\n",
    "    df_result_majority[\"cumprob\"] = np.cumsum(df_result_majority[\"prob\"])\n",
    "    return df_result_majority\n",
    "\n",
    "# demo cot 4-shot ICL GSM8K testset Q10 \n",
    "def Davinci_openai_stop(prompt, stop_index):\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-002\",prompt = prompt, temperature = 1,\n",
    "    max_tokens=1024, top_p=1, frequency_penalty=0,\n",
    "    presence_penalty=0,logprobs = 5,\n",
    "    stop = stop_index)\n",
    "    return response\n",
    "\n",
    "def Davinci_openai(prompt):\n",
    "    response = openai.Completion.create(\n",
    "    model=\"text-davinci-002\",prompt = prompt, temperature = 1,\n",
    "    max_tokens=32, top_p=1, frequency_penalty=0,\n",
    "    presence_penalty=0,logprobs = 5)\n",
    "    return response\n",
    "\n",
    "def answer_diversity(ans_prompt,n_round = 3):\n",
    "    count = 0 \n",
    "    dic_result = {}\n",
    "    while count < n_round:\n",
    "        index_front  = -100\n",
    "        index_end = 100 \n",
    "        ans_generation = Davinci_openai(ans_prompt)\n",
    "        if (\"{\" in ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"]):\n",
    "            index_front =  ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"].index(\"{\")\n",
    "        if (\" {\" in ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"]):\n",
    "            index_front =  ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"].index(\" {\")\n",
    "\n",
    "        if (\"}\" in ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"]):\n",
    "            index_end =  ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"].index(\"}\")\n",
    "        if (\"} \" in ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"]):\n",
    "            index_end =  ans_generation[\"choices\"][0][\"logprobs\"][\"tokens\"].index(\"} \")\n",
    "        \n",
    "        if index_end - index_front == 2: \n",
    "            dic_result[count] = ans_generation\n",
    "            count += 1 \n",
    "    return dic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_check(i,step_reasoning_list, n_shot_num = 4, n_step_num = 3):\n",
    "\n",
    "    # answer entropy check\n",
    "    ans_prompt = n_shot_prompt_generator_GSM8K_reason(n_shot_num ,n_step_num ,GSM8K_test_df[\"question\"][i], GSM8K_train_df_reason, False, len(step_reasoning_list), True) \n",
    "\n",
    "    for _ in step_reasoning_list:\n",
    "        ans_prompt += '\\n'\n",
    "        ans_prompt += _[\"choices\"][0][\"text\"]\n",
    "    ans_prompt += \"\\nThe answer is\"\n",
    "\n",
    "    ## sample \n",
    "    dic_result = answer_diversity(ans_prompt)\n",
    "\n",
    "    ## dataprocessing\n",
    "    df_summary = entropy_df_generation(dic_result)\n",
    "\n",
    "    ## entrpy check\n",
    "    entropy_value = entropy(df_summary[\"prob\"])\n",
    "    print(entropy_value)\n",
    "    return ans_prompt, dic_result, df_summary, entropy_value\n",
    "\n",
    "from functools import reduce  # forward compatibility for Python 3\n",
    "import operator\n",
    "\n",
    "def getFromDict(dataDict, mapList):\n",
    "    return reduce(operator.getitem, mapList, dataDict)\n",
    "\n",
    "def setInDict(dataDict, mapList, value):\n",
    "    getFromDict(dataDict, mapList[:-1])[mapList[-1]] = value\n",
    "\n",
    "def belif_change_index(dist1, dist2):\n",
    "    index = 0\n",
    "    token_list = list(set(dist1[\"token\"]) | set(dist2[\"token\"]))\n",
    "    for i in token_list:\n",
    "        if (i in list(dist1[\"token\"])) and (i in list(dist2[\"token\"])):\n",
    "            index1 = list(dist1[\"token\"]).index(i)\n",
    "            index2 = list(dist2[\"token\"]).index(i)\n",
    "            index += np.abs(dist1[\"prob\"][index1] - dist2[\"prob\"][index2])\n",
    "\n",
    "        elif (i not in list(dist1[\"token\"])) and (i in list(dist2[\"token\"])):\n",
    "            index2 = list(dist2[\"token\"]).index(i)\n",
    "            index += np.abs(dist2[\"prob\"][index2])        \n",
    "        else:\n",
    "            index1 = list(dist1[\"token\"]).index(i)\n",
    "            index += np.abs(dist1[\"prob\"][index1])     \n",
    "    return(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(tmp_book,entropy_level = 1):\n",
    "    layer_number = int(tmp_book[\"layer\"].split(\"{\")[1][0])\n",
    "    step_str = \"Step{\"+str(layer_number+1) + \"}Num\"\n",
    "    tmp = {}  \n",
    "    tmp[step_str] = 0\n",
    "    entropy_score = 10 \n",
    "    # intial prompt \n",
    "    count = 0 \n",
    "    print(\"In Step \" + str(layer_number) + \"\\n\")\n",
    "\n",
    "    entropy_value = tmp_book[\"Status\"][-1]\n",
    "    dist1 = tmp_book[\"Status\"][2]\n",
    "    prompt = tmp_book[\"prompt\"]\n",
    "    step_reasoning = tmp_book[\"step_reasoning\"]\n",
    "    prompt += step_reasoning['choices'][0][\"text\"]\n",
    "\n",
    "    while (entropy_score > entropy_level) &  (count < 2):\n",
    "        step_reasoning_list = tmp_book[\"step_reasoning_list\"].copy()\n",
    "        print(\"-----------------------------------------------------\") \n",
    "        step_reasoning = Davinci_openai_stop(prompt,[\"Step \"+str(layer_number+2)])\n",
    "        step_reasoning_list.append(step_reasoning)\n",
    "        print('-------------------------------------------')\n",
    "        for i in step_reasoning_list:\n",
    "            print(i['choices'][0][\"text\"])\n",
    "        print('-------------------------------------------')\n",
    "        print(step_reasoning['choices'][0][\"text\"])   \n",
    "        ans1 = entropy_check(question_index,step_reasoning_list , n_shot, n_step)\n",
    "        dist2 = ans1[2]\n",
    "        tmp[count] = {}\n",
    "        tmp[count][\"prompt\"] = prompt\n",
    "        tmp[count][\"Status\"] = ans1\n",
    "        tmp[count][\"step_reasoning\"] = step_reasoning \n",
    "        tmp[count][\"step_reasoning_list\"] = step_reasoning_list\n",
    "        tmp[step_str] += 1\n",
    "        tmp[count][\"layer\"] = step_str\n",
    "        tmp[count][\"belif\"] = belif_change_index(dist1, dist2)\n",
    "        print(\"Change of Belif: \" + str(tmp[count][\"belif\"]))\n",
    "        count += 1\n",
    "        print(\"In \" + str(layer_number+1) +   \" Step Generate: \"+str(count))\n",
    "        entropy_score = ans1[-1]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo \n",
    "n_round = 3\n",
    "i = 9 \n",
    "n_step = 3\n",
    "n_shot = 4\n",
    "\n",
    "step_reasoning_list = []\n",
    "# print the prompt and generated answer\n",
    "prompt = n_shot_prompt_generator_GSM8K_reason(n_shot,n_step,GSM8K_test_df[\"question\"][i], GSM8K_train_df_reason, False, n_step, False)\n",
    "print(\"-----------------------------------------------------\")\n",
    "# step 1 generation \n",
    "step_reasoning = Davinci_openai_stop(prompt,[\"Step 2\"])\n",
    "step_reasoning_list.append(step_reasoning)\n",
    "print(step_reasoning['choices'][0][\"text\"])\n",
    "\n",
    "ans1 = entropy_check(i,step_reasoning_list , n_shot, n_step)\n",
    "\n",
    "# new next prompt \n",
    "prompt = prompt + step_reasoning[\"choices\"][0][\"text\"]\n",
    "\n",
    "# step 2\n",
    "print(\"-----------------------------------------------------\")\n",
    "step_reasoning = Davinci_openai_stop(prompt,[\"Step 3\"])\n",
    "step_reasoning_list.append(step_reasoning)\n",
    "print(step_reasoning['choices'][0][\"text\"])\n",
    "\n",
    "ans2 = entropy_check(i,step_reasoning_list , n_shot, n_step)\n",
    "\n",
    "\n",
    "# new next prompt\n",
    "prompt = prompt + step_reasoning[\"choices\"][0][\"text\"]\n",
    "\n",
    "# step 3\n",
    "print(\"-----------------------------------------------------\")\n",
    "step_reasoning = Davinci_openai_stop(prompt,[\"Step 4\"])\n",
    "step_reasoning_list.append(step_reasoning)\n",
    "print(step_reasoning['choices'][0][\"text\"])\n",
    "\n",
    "ans3 = entropy_check(i,step_reasoning_list , n_shot, n_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_total = 3\n",
    "\n",
    "n_round = 3\n",
    "question_index = 9 \n",
    "n_step = 3\n",
    "n_shot = 4\n",
    "tree_structure = {}\n",
    "\n",
    "record_index_list = []\n",
    "record_dic_total = {}\n",
    "divide_list = []\n",
    "index_dic = 0\n",
    "\n",
    "for layer_index in range(layer_total):\n",
    "    if layer_index == 0:\n",
    "        tmp_list = []\n",
    "        n_round = 3\n",
    "        question_index = 9 \n",
    "        n_step = 3\n",
    "        n_shot = 4\n",
    "\n",
    "        log_book = {}\n",
    "        step_str = \"Step{\"+str(1) + \"}Num\"\n",
    "        print(step_str)\n",
    "        # print the prompt and generated answer\n",
    "        log_book[step_str] = 0\n",
    "\n",
    "        entropy_score = 5 \n",
    "        # intial prompt \n",
    "        count = 0 \n",
    "        while (entropy_score > 0.6) &  (count < 2):\n",
    "            step_reasoning_list = []\n",
    "            prompt = n_shot_prompt_generator_GSM8K_reason(n_shot,n_step,GSM8K_test_df[\"question\"][question_index], GSM8K_train_df_reason, False, n_step, False)\n",
    "            print(\"-----------------------------------------------------\")\n",
    "            # step 1 generation \n",
    "            step_reasoning = Davinci_openai_stop(prompt,[\"Step 2\"])\n",
    "            step_reasoning_list.append(step_reasoning)\n",
    "            print(step_reasoning['choices'][0][\"text\"])\n",
    "            \n",
    "            ans1 = entropy_check(question_index,step_reasoning_list , n_shot, n_step)\n",
    "            tree_structure[count] = {}\n",
    "            log_book[count] = {}\n",
    "            log_book[count][\"prompt\"] = prompt\n",
    "            log_book[count][\"Status\"] = ans1\n",
    "            log_book[count][\"step_reasoning\"] = step_reasoning \n",
    "            log_book[count][\"step_reasoning_list\"] = step_reasoning_list\n",
    "            print('-------------------------------------------')\n",
    "            for i in step_reasoning_list:\n",
    "                print(i['choices'][0][\"text\"])\n",
    "            print('-------------------------------------------')\n",
    "            log_book[step_str] += 1\n",
    "            log_book[count][\"layer\"] = step_str\n",
    "            tmp_list.append(count)\n",
    "            record_dic_total[index_dic] = log_book[count] \n",
    "            index_dic += 1\n",
    "            count += 1\n",
    "            print(\"In first Step Generate: \"+str(count))\n",
    "            entropy_score = ans1[-1]\n",
    "        record_index_list.append(tmp_list)\n",
    "    else:\n",
    "        tmp_list = []\n",
    "        tmp_list2 = []\n",
    "        step_str = \"Step{\"+str(layer_index+1) + \"}Num\"\n",
    "        print(step_str)\n",
    "        for i in record_index_list[-1]:\n",
    "            tmp_book_i = record_dic_total[i]\n",
    "            ans = iteration(tmp_book_i, 0.001) \n",
    "            tmp_num = ans[step_str] \n",
    "            for j in range(tmp_num):\n",
    "                record_dic_total[index_dic] = ans[j]\n",
    "                tmp_list.append(index_dic)\n",
    "                index_dic += 1 \n",
    "            tmp_list2.append(index_dic)\n",
    "        divide_list.append(tmp_list2)\n",
    "        record_index_list.append(tmp_list) \n",
    "for i,j in enumerate(divide_list):\n",
    "    divide_list[i] = [k - 1 for k in j]\n",
    "\n",
    "adjusted_list = []\n",
    "\n",
    "for i in range(layer_total):\n",
    "    if i !=0 :\n",
    "        sub_list = record_index_list[i].copy()\n",
    "        sub_divide = divide_list[i-1].copy()\n",
    "        tmp1 = []\n",
    "        tmp = []\n",
    "        for j in sub_list:\n",
    "            if len(sub_divide) != 0:\n",
    "                if j == sub_divide[0]:\n",
    "                    sub_divide.remove(sub_divide[0])\n",
    "                    tmp.append(j)\n",
    "                    tmp1.append(tmp)\n",
    "                    tmp = []\n",
    "                else:\n",
    "                    tmp.append(j)\n",
    "            \n",
    "        adjusted_list.append(tmp1)\n",
    "    else:\n",
    "        adjusted_list.append(record_index_list[i])\n",
    "\n",
    "log_book_copy = log_book.copy()\n",
    "for i in np.arange(len(adjusted_list)-1, -1, -1):\n",
    "    if i == 0:\n",
    "        break\n",
    "        tmp_list = adjusted_list[i+1]\n",
    "        step_str = \"Step{\"+str(i+1) + \"}Num\"\n",
    "        for j, sub_list in enumerate(tmp_list):\n",
    "            setInDict(log_book_copy, [j,\"Next\"], {})\n",
    "            setInDict(log_book_copy, [j,\"Next\",step_str], len(sub_list))\n",
    "            for k, dic in enumerate(sub_list):\n",
    "                setInDict(log_book_copy, [j,\"Next\", k], record_dic_total[dic])\n",
    "    elif i == 1: \n",
    "        step_str = \"Step{\"+str(i+1) + \"}Num\"\n",
    "        for j, position_j in enumerate(record_index_list[i-1]):\n",
    "            dic = record_dic_total[position_j]\n",
    "            setInDict(dic, [\"Next\"], {})\n",
    "            setInDict(dic, [\"Next\",step_str], len(sub_list))\n",
    "            for k, position_k in enumerate(adjusted_list[i][j]):\n",
    "                setInDict(dic, [\"Next\", k], record_dic_total[position_k])\n",
    "            log_book_copy[position_j] = dic         \n",
    "    else:\n",
    "        step_str = \"Step{\"+str(i+1) + \"}Num\"\n",
    "        for j, position_j in enumerate(record_index_list[i-1]):\n",
    "            dic = record_dic_total[position_j]\n",
    "            setInDict(dic, [\"Next\"], {})\n",
    "            setInDict(dic, [\"Next\",step_str], len(sub_list))\n",
    "            for k, position_k in enumerate(adjusted_list[i][j]):\n",
    "                setInDict(dic, [\"Next\", k], record_dic_total[position_k])\n",
    "            record_dic_total[position_j] = dic "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chain_of_Information",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
